{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cebuano Stemmer Demo\n",
    "\n",
    "`Accepts a Cebuano word and returns the root word and its affixes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a Cebuano word: gipakaon\n",
      "gipakaon:[(paka), {gi,-,on}]\n"
     ]
    }
   ],
   "source": [
    "from stemmer import stem_word\n",
    "\n",
    "ceb_word = raw_input('Input a Cebuano word: ')\n",
    "word = stem_word(word=ceb_word)\n",
    "\n",
    "print(word.print_stem_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cebuano POS Tagger Demo\n",
    "\n",
    "`Accepts a Cebuano sentence and return POS tagged sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a Cebuano sentence: Gipakaon ko niya og kanon.\n",
      "gipakaon/['NOUN'] ko/['PRON'] niya/['PRON'] og/['CONJ'] kanon/['ADV'] ./['SYM'] \n"
     ]
    }
   ],
   "source": [
    "from tagger import tag_sentence\n",
    "\n",
    "ceb_sentence = raw_input('Input a Cebuano sentence: ')\n",
    "words = tag_sentence(text=ceb_sentence)\n",
    "\n",
    "sentence = ''\n",
    "for word in words:\n",
    "    sentence += str(word) + ' '\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemmer Evaluation\n",
    "\n",
    "\n",
    "`Evaluates the stemmer by getting the number of predicted root words vs. actual root words`\n",
    "\n",
    "* The input words are already tokenized and stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 1298\n",
      "Correct root words: 955\n",
      "Incorrect root words: 343\n",
      "Correct / incorrect root percentage: 73.57473035439138\n",
      "\n",
      "\n",
      "Dictionary entry tokens: 974\n",
      "Correct dictionary entry tokens: 878\n",
      "Incorrect dictionary entry tokens: 96\n",
      "\n",
      "\n",
      "Non-dictionary entry tokens: 324\n",
      "Correct non-dictionary entry tokens: 77\n",
      "Incorrect non-dictionary entry tokens: 247\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infix</th>\n",
       "      <th>is_entry</th>\n",
       "      <th>is_root</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>prefix</th>\n",
       "      <th>root</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nipahibawo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ni</td>\n",
       "      <td>pahibaw</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naghuwat</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>nag</td>\n",
       "      <td>huwat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsaon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsa</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mamahimong</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ma</td>\n",
       "      <td>himo</td>\n",
       "      <td>ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syudad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>syudad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sirhan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sir</td>\n",
       "      <td>han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kalapasan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ka</td>\n",
       "      <td>lapas</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bawian</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ba</td>\n",
       "      <td>wi</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nakalapas</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>naka</td>\n",
       "      <td>lapas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nagkadaiyang</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>nag</td>\n",
       "      <td>kadaiya</td>\n",
       "      <td>ng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             infix  is_entry  is_root  is_valid prefix     root suffix\n",
       "nipahibawo     NaN     False    False     False     ni  pahibaw      o\n",
       "naghuwat       NaN      True    False      True    nag    huwat    NaN\n",
       "unsaon         NaN      True    False      True    NaN     unsa     on\n",
       "mamahimong     NaN      True    False      True     ma     himo     ng\n",
       "syudad         NaN      True     True      True    NaN   syudad    NaN\n",
       "sirhan         NaN      True    False     False    NaN      sir    han\n",
       "kalapasan      NaN      True    False      True     ka    lapas     an\n",
       "bawian         NaN     False    False     False     ba       wi     an\n",
       "nakalapas      NaN      True    False      True   naka    lapas    NaN\n",
       "nagkadaiyang   NaN      True    False     False    nag  kadaiya     ng"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stemmer_evaluator as se\n",
    "import pandas as pd\n",
    "\n",
    "result = se.to_panda_data()\n",
    "\n",
    "df = pd.DataFrame(result['data'], index=result['index'])\n",
    "df_valid = df[(df.is_valid == True)]\n",
    "valid = df_valid.count()['is_valid']\n",
    "print('Total tokens: ' + str(df.count()['is_valid']))\n",
    "print('Correct root words: ' + str(df[(df.is_valid == True)].count()['is_valid']))\n",
    "print('Incorrect root words: ' + str(df[(df.is_valid == False)].count()['is_valid']))\n",
    "print(\"Correct / incorrect root percentage: \" + str((valid / float(df.count()['is_valid'])) * 100))\n",
    "print('\\n')\n",
    "print('Dictionary entry tokens: ' + str(df[(df.is_entry == True)].count()['is_entry']))\n",
    "print('Correct dictionary entry tokens: ' + str(df[(df.is_entry == True) & (df.is_valid == True)].count()['is_entry']))\n",
    "print('Incorrect dictionary entry tokens: ' + str(df[(df.is_entry == True) & (df.is_valid == False)].count()['is_entry']))\n",
    "print('\\n')\n",
    "print('Non-dictionary entry tokens: ' + str(df[(df.is_entry == False)].count()['is_entry']))\n",
    "print('Correct non-dictionary entry tokens: ' + str(df[(df.is_entry == False) & (df.is_valid == True)].count()['is_entry']))\n",
    "print('Incorrect non-dictionary entry tokens: ' + str(df[(df.is_entry == False) & (df.is_valid == False)].count()['is_entry']))\n",
    "print('\\n')\n",
    "\n",
    "df.tail(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger Evaluation\n",
    "\n",
    "\n",
    "`Evaluates the tagger by getting the number of predicted pos tags vs. actual pos tags (F-score)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"polyglot.detect.base\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 1220\n",
      "\n",
      "Disambiguated: 100.0% (1220) \n",
      "\n",
      "Predicted  ADJ  ADV  CONJ  DET  NOUN  NUM  OTH  PART  PRON  SYM  VERB  __all__\n",
      "Actual                                                                        \n",
      "ADJ         34    4     0    0     7    0    3     1     0    0     4       53\n",
      "ADV          0   82     0    0     5    0    0     0     1    0     4       92\n",
      "CONJ         0    0    48    0     0    0    0     4     0    0     0       52\n",
      "DET          0    0    11   70     0    0    2     0     0    0     0       83\n",
      "NOUN         4    0     1    1   234    0   45     1     0    0    28      314\n",
      "NUM          0    0     0    0     9   28    1     0     0    0     0       38\n",
      "OTH          0    0     0    0     0    0    3     0     0    0     0        3\n",
      "PART         0    1     1    1     0    0    1   285     9    0     5      303\n",
      "PRON         0    0     0    0     0    0    1     0    51    0     0       52\n",
      "SYM          0    0     0    0     0    0    0     0     0   87     0       87\n",
      "VERB         8    1     0    0    11    0   23     0     6    0    94      143\n",
      "__all__     46   88    61   72   266   28   79   291    67   87   135     1220\n",
      "\n",
      "Overall F-Score\n",
      "\n",
      "0.8327868852459016\n",
      "\n",
      "\n",
      "Individual F-Score\n",
      "\n",
      "ADJ  : 0.6868686868686867\n",
      "ADV  : 0.9111111111111111\n",
      "CONJ : 0.8495575221238939\n",
      "DET  : 0.903225806451613\n",
      "NOUN : 0.8068965517241379\n",
      "NUM  : 0.8484848484848484\n",
      "OTH  : 0.07317073170731708\n",
      "PART : 0.9595959595959594\n",
      "PRON : 0.8571428571428572\n",
      "SYM  : 1.0\n",
      "VERB : 0.6762589928057553\n"
     ]
    }
   ],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import f1_score\n",
    "import tagger_evaluator as te\n",
    "\n",
    "words = te.tag_test_sentences()\n",
    "y_true = te.extract_actual_pos_tags()\n",
    "y_pred = te.extract_predicted_pos_tags(words=words)\n",
    "confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "# confusion_matrix.print_stats()\n",
    "print(confusion_matrix)\n",
    "\n",
    "print('\\nOverall F-Score\\n')\n",
    "f1score = f1_score(y_true, y_pred, average='micro')\n",
    "print(f1score)\n",
    "print('\\n')\n",
    "\n",
    "df = f1_score(y_true, y_pred, average=None)\n",
    "print('Individual F-Score' + '\\n')\n",
    "print('ADJ  : ' + str(df[0]))\n",
    "print('ADV  : ' + str(df[1]))\n",
    "print('CONJ : ' + str(df[2]))\n",
    "print('DET  : ' + str(df[3]))\n",
    "print('NOUN : ' + str(df[4]))\n",
    "print('NUM  : ' + str(df[5]))\n",
    "print('OTH  : ' + str(df[6]))\n",
    "print('PART : ' + str(df[7]))\n",
    "print('PRON : ' + str(df[8]))\n",
    "print('SYM  : ' + str(df[9]))\n",
    "print('VERB : ' + str(df[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
