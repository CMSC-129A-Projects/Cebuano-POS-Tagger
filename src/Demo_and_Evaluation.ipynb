{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cebuano Stemmer Demo\n",
    "\n",
    "`Accepts a Cebuano word and returns the root word and its affixes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a Cebuano word: malinawon\n",
      "malinawon:[(linaw), {ma,-,on}]\n"
     ]
    }
   ],
   "source": [
    "from stemmer import stem_word\n",
    "\n",
    "ceb_word = raw_input('Input a Cebuano word: ')\n",
    "word = stem_word(word=ceb_word)\n",
    "\n",
    "print(word.print_stem_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cebuano POS Tagger Demo\n",
    "\n",
    "`Accepts a Cebuano sentence and return POS tagged sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a Cebuano sentence: bagag nawong ka.\n",
      "bagag/['ADJ'] nawong/['NOUN'] ka/['PRON', 'PART'] ./['SYM'] \n"
     ]
    }
   ],
   "source": [
    "from tagger import tag_sentence\n",
    "\n",
    "ceb_sentence = raw_input('Input a Cebuano sentence: ')\n",
    "words = tag_sentence(text=ceb_sentence)\n",
    "\n",
    "sentence = ''\n",
    "for word in words:\n",
    "    sentence += str(word) + ' '\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemmer Evaluation\n",
    "\n",
    "\n",
    "`Evaluates the stemmer by getting the number of predicted root words vs. actual root words`\n",
    "\n",
    "* The input words are already tokenized and stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 1298\n",
      "Correct root words: 955\n",
      "Incorrect root words: 343\n",
      "Correct / incorrect root percentage: 73.57473035439138\n",
      "\n",
      "\n",
      "Dictionary entry tokens: 974\n",
      "Correct dictionary entry tokens: 878\n",
      "Incorrect dictionary entry tokens: 96\n",
      "\n",
      "\n",
      "Non-dictionary entry tokens: 324\n",
      "Correct non-dictionary entry tokens: 77\n",
      "Incorrect non-dictionary entry tokens: 247\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infix</th>\n",
       "      <th>is_entry</th>\n",
       "      <th>is_root</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>prefix</th>\n",
       "      <th>root</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nipahibawo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ni</td>\n",
       "      <td>pahibaw</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naghuwat</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>nag</td>\n",
       "      <td>huwat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsaon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsa</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mamahimong</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ma</td>\n",
       "      <td>himo</td>\n",
       "      <td>ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syudad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>syudad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sirhan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sir</td>\n",
       "      <td>han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kalapasan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ka</td>\n",
       "      <td>lapas</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bawian</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ba</td>\n",
       "      <td>wi</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nakalapas</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>naka</td>\n",
       "      <td>lapas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nagkadaiyang</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>nag</td>\n",
       "      <td>kadaiya</td>\n",
       "      <td>ng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             infix  is_entry  is_root  is_valid prefix     root suffix\n",
       "nipahibawo     NaN     False    False     False     ni  pahibaw      o\n",
       "naghuwat       NaN      True    False      True    nag    huwat    NaN\n",
       "unsaon         NaN      True    False      True    NaN     unsa     on\n",
       "mamahimong     NaN      True    False      True     ma     himo     ng\n",
       "syudad         NaN      True     True      True    NaN   syudad    NaN\n",
       "sirhan         NaN      True    False     False    NaN      sir    han\n",
       "kalapasan      NaN      True    False      True     ka    lapas     an\n",
       "bawian         NaN     False    False     False     ba       wi     an\n",
       "nakalapas      NaN      True    False      True   naka    lapas    NaN\n",
       "nagkadaiyang   NaN      True    False     False    nag  kadaiya     ng"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stemmer_evaluator as se\n",
    "import pandas as pd\n",
    "\n",
    "result = se.to_panda_data()\n",
    "\n",
    "df = pd.DataFrame(result['data'], index=result['index'])\n",
    "df_valid = df[(df.is_valid == True)]\n",
    "valid = df_valid.count()['is_valid']\n",
    "print('Total tokens: ' + str(df.count()['is_valid']))\n",
    "print('Correct root words: ' + str(df[(df.is_valid == True)].count()['is_valid']))\n",
    "print('Incorrect root words: ' + str(df[(df.is_valid == False)].count()['is_valid']))\n",
    "print(\"Correct / incorrect root percentage: \" + str((valid / float(df.count()['is_valid'])) * 100))\n",
    "print('\\n')\n",
    "print('Dictionary entry tokens: ' + str(df[(df.is_entry == True)].count()['is_entry']))\n",
    "print('Correct dictionary entry tokens: ' + str(df[(df.is_entry == True) & (df.is_valid == True)].count()['is_entry']))\n",
    "print('Incorrect dictionary entry tokens: ' + str(df[(df.is_entry == True) & (df.is_valid == False)].count()['is_entry']))\n",
    "print('\\n')\n",
    "print('Non-dictionary entry tokens: ' + str(df[(df.is_entry == False)].count()['is_entry']))\n",
    "print('Correct non-dictionary entry tokens: ' + str(df[(df.is_entry == False) & (df.is_valid == True)].count()['is_entry']))\n",
    "print('Incorrect non-dictionary entry tokens: ' + str(df[(df.is_entry == False) & (df.is_valid == False)].count()['is_entry']))\n",
    "print('\\n')\n",
    "\n",
    "df.tail(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger Evaluation\n",
    "\n",
    "\n",
    "`Evaluates the tagger by getting the number of predicted pos tags vs. actual pos tags (F-score)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karon/['ADV', 'ADJ']\n",
      "langyaw/['NOUN', 'VERB', 'ADJ']\n",
      "wa/['ADV', 'ADJ']\n",
      "og/['CONJ', 'DET']\n",
      "igong/['VERB', 'ADJ']\n",
      "nganong/['ADV', 'PRON']\n",
      "kuyog/['VERB', 'NOUN']\n",
      "duna/['VERB', 'ADJ']\n",
      "tuyo/['VERB', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "sugbo/['VERB', 'NOUN']\n",
      "maong/['VERB', 'NOUN']\n",
      "kuyog/['VERB', 'NOUN']\n",
      "menor/['NOUN', 'VERB', 'ADJ']\n",
      "og/['CONJ', 'DET']\n",
      "ug/['CONJ', 'DET']\n",
      "ka/['PRON', 'PART']\n",
      "og/['CONJ', 'DET']\n",
      "ug/['CONJ', 'DET']\n",
      "ug/['CONJ', 'DET']\n",
      "og/['CONJ', 'DET']\n",
      "langyaw/['NOUN', 'VERB', 'ADJ']\n",
      "maong/['VERB', 'NOUN']\n",
      "ug/['CONJ', 'DET']\n",
      "bogo/['NOUN', 'ADJ']\n",
      "human/['ADV', 'VERB', 'ADJ']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "kuyog/['VERB', 'NOUN']\n",
      "langyaw/['NOUN', 'VERB', 'ADJ']\n",
      "langyaw/['NOUN', 'VERB', 'ADJ']\n",
      "ug/['CONJ', 'DET']\n",
      "og/['CONJ', 'DET']\n",
      "langyaw/['NOUN', 'VERB', 'ADJ']\n",
      "kuyog/['VERB', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "pabuto/['VERB', 'NOUN']\n",
      "way/['ADV', 'ADJ']\n",
      "tungod/['CONJ', 'PART']\n",
      "bala/['NOUN', 'VERB', 'ADJ']\n",
      "sukad/['ADV', 'VERB']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "ka/['PRON', 'PART']\n",
      "og/['CONJ', 'DET']\n",
      "pabuto/['VERB', 'NOUN']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "ug/['CONJ', 'DET']\n",
      "og/['CONJ', 'DET']\n",
      "ug/['CONJ', 'DET']\n",
      "capitan/['VERB', 'ADJ']\n",
      "tuo/['ADV', 'VERB', 'ADJ']\n",
      "mata/['VERB', 'NOUN']\n",
      "wa/['ADV', 'ADJ']\n",
      "asa/['ADV', 'PRON', 'VERB']\n",
      "o/['CONJ', 'PART']\n",
      "samad/['VERB', 'NOUN']\n",
      "bahin/['VERB', 'NOUN']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "diin/['ADV', 'PRON']\n",
      "human/['ADV', 'VERB', 'ADJ']\n",
      "bala/['NOUN', 'VERB', 'ADJ']\n",
      "ug/['CONJ', 'DET']\n",
      "luwas/['VERB', 'ADJ']\n",
      "bag-ong/['VERB', 'NOUN']\n",
      "ug/['CONJ', 'DET']\n",
      "menos/['NOUN', 'ADJ']\n",
      "pabuto/['VERB', 'NOUN']\n",
      "tungod/['CONJ', 'PART']\n",
      "ug/['CONJ', 'DET']\n",
      "wa/['ADV', 'ADJ']\n",
      "grabeng/['ADV', 'ADJ', 'NOUN']\n",
      "labing/['ADV', 'ADJ']\n",
      "minos/['NOUN', 'ADJ']\n",
      "ka/['PRON', 'PART']\n",
      "wa/['ADV', 'ADJ']\n",
      "hapit/['ADV', 'VERB']\n",
      "nianang/['PRON', 'PART']\n",
      "la/['VERB', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "dapit/['VERB', 'NOUN']\n",
      "ubos/['ADV', 'ADJ']\n",
      "la/['VERB', 'NOUN']\n",
      "way/['ADV', 'ADJ']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "tungod/['CONJ', 'PART']\n",
      "nanawag/['ADV', 'ADJ']\n",
      "tinuod/['ADV', 'ADJ', 'NOUN']\n",
      "way/['ADV', 'ADJ']\n",
      "og/['CONJ', 'DET']\n",
      "human/['ADV', 'VERB', 'ADJ']\n",
      "lahos/['ADV', 'VERB', 'NOUN']\n",
      "og/['CONJ', 'DET']\n",
      "ka/['PRON', 'PART']\n",
      "nianang/['PRON', 'PART']\n",
      "grabeng/['ADV', 'ADJ', 'NOUN']\n",
      "maong/['VERB', 'NOUN']\n",
      "walay/['ADV', 'ADJ']\n",
      "igo/['VERB', 'ADJ']\n",
      "ug/['CONJ', 'DET']\n",
      "human/['ADV', 'VERB', 'ADJ']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "alas/['ADV', 'NOUN']\n",
      "alas/['ADV', 'NOUN']\n",
      "hapit/['ADV', 'VERB']\n",
      "tungod/['CONJ', 'PART']\n",
      "alas/['ADV', 'NOUN']\n",
      "pasado/['NOUN', 'ADJ']\n",
      "tungod/['CONJ', 'PART']\n",
      "bag-ong/['VERB', 'NOUN']\n",
      "ug/['CONJ', 'DET']\n",
      "karon/['ADV', 'ADJ']\n",
      "og/['CONJ', 'DET']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "nganong/['ADV', 'PRON']\n",
      "tungod/['CONJ', 'PART']\n",
      "grabeng/['ADV', 'ADJ', 'NOUN']\n",
      "anaa/['PRON', 'PART']\n",
      "ka/['PRON', 'PART']\n",
      "og/['CONJ', 'DET']\n",
      "ug/['CONJ', 'DET']\n",
      "anaa/['PRON', 'PART']\n",
      "tungod/['CONJ', 'PART']\n",
      "sugbo/['VERB', 'NOUN']\n",
      "grabeng/['ADV', 'ADJ', 'NOUN']\n",
      "nganong/['ADV', 'PRON']\n",
      "ug/['CONJ', 'DET']\n",
      "nganong/['ADV', 'PRON']\n",
      "daghan/['ADV', 'ADJ', 'NOUN']\n",
      "og/['CONJ', 'DET']\n",
      "butang/['VERB', 'NOUN']\n",
      "ug/['CONJ', 'DET']\n",
      "diin/['ADV', 'PRON']\n",
      "grabeng/['ADV', 'ADJ', 'NOUN']\n",
      "way/['ADV', 'ADJ']\n",
      "maong/['VERB', 'NOUN']\n",
      "tungod/['CONJ', 'PART']\n",
      "wa/['ADV', 'ADJ']\n",
      "ug/['CONJ', 'DET']\n",
      "wa/['ADV', 'ADJ']\n",
      "hapit/['ADV', 'VERB']\n",
      "padung/['VERB', 'NOUN']\n",
      "ug/['CONJ', 'DET']\n",
      "sugbo/['VERB', 'NOUN']\n",
      "patay/['VERB', 'NOUN']\n",
      "usa/['ADV', 'NUM', 'NOUN']\n",
      "ka/['PRON', 'PART']\n",
      "ug/['CONJ', 'DET']\n",
      "Number of tokens: 1220\n",
      "\n",
      "Disambiguated: 87.7049180328% (1070) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajrequina/virtualenvs/cebpos/local/lib/python2.7/site-packages/pandas_ml/confusion_matrix/bcm.py:346: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return(np.float64(self.LRP) / self.LRN)\n",
      "/home/ajrequina/virtualenvs/cebpos/local/lib/python2.7/site-packages/pandas_ml/confusion_matrix/bcm.py:332: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  ADJ  ADV  CONJ  DET  NOUN  NUM  OTH  PART  PRON  SYM  VERB  __all__\n",
      "Actual                                                                        \n",
      "ADJ         29    9     0    0     4    0    3     1     0    0     7       53\n",
      "ADV          0   90     0    0     1    0    0     0     0    0     1       92\n",
      "CONJ         0    0    52    0     0    0    0     0     0    0     0       52\n",
      "DET          0    0    11   70     0    0    2     0     0    0     0       83\n",
      "NOUN         3    0     1    1   222    0   48     1     0    0    38      314\n",
      "NUM          0    8     0    0     1   28    1     0     0    0     0       38\n",
      "OTH          0    0     0    0     0    0    3     0     0    0     0        3\n",
      "PART         0    1     2    1     0    0    1   276    17    0     5      303\n",
      "PRON         0    1     0    0     0    0    1     0    50    0     0       52\n",
      "SYM          0    0     0    0     0    0    0     0     0   87     0       87\n",
      "VERB         7    1     0    0     8    0   24     0     4    0    99      143\n",
      "__all__     39  110    66   72   236   28   83   278    71   87   150     1220\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.8245901639344262\n",
      "95% CI: (0.8020647077854607, 0.8455385682157636)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 0.0\n",
      "Kappa: 0.7951418776673417\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       ADJ        ADV       CONJ  \\\n",
      "Population                                   1220       1220       1220   \n",
      "P: Condition positive                          53         92         52   \n",
      "N: Condition negative                        1167       1128       1168   \n",
      "Test outcome positive                          39        110         66   \n",
      "Test outcome negative                        1181       1110       1154   \n",
      "TP: True Positive                              29         90         52   \n",
      "TN: True Negative                            1157       1108       1154   \n",
      "FP: False Positive                             10         20         14   \n",
      "FN: False Negative                             24          2          0   \n",
      "TPR: (Sensitivity, hit rate, recall)      0.54717   0.978261          1   \n",
      "TNR=SPC: (Specificity)                   0.991431    0.98227   0.988014   \n",
      "PPV: Pos Pred Value (Precision)           0.74359   0.818182   0.787879   \n",
      "NPV: Neg Pred Value                      0.979678   0.998198          1   \n",
      "FPR: False-out                         0.00856898  0.0177305  0.0119863   \n",
      "FDR: False Discovery Rate                 0.25641   0.181818   0.212121   \n",
      "FNR: Miss Rate                            0.45283  0.0217391          0   \n",
      "ACC: Accuracy                            0.972131   0.981967   0.988525   \n",
      "F1 score                                 0.630435   0.891089   0.881356   \n",
      "MCC: Matthews correlation coefficient    0.624142   0.885527    0.88229   \n",
      "Informedness                             0.538601    0.96053   0.988014   \n",
      "Markedness                               0.723268    0.81638   0.787879   \n",
      "Prevalence                              0.0434426  0.0754098   0.042623   \n",
      "LR+: Positive likelihood ratio            63.8547    55.1739    83.4286   \n",
      "LR-: Negative likelihood ratio           0.456744  0.0221315          0   \n",
      "DOR: Diagnostic odds ratio                139.804       2493        inf   \n",
      "FOR: False omission rate                0.0203218  0.0018018          0   \n",
      "\n",
      "Classes                                       DET       NOUN         NUM  \\\n",
      "Population                                   1220       1220        1220   \n",
      "P: Condition positive                          83        314          38   \n",
      "N: Condition negative                        1137        906        1182   \n",
      "Test outcome positive                          72        236          28   \n",
      "Test outcome negative                        1148        984        1192   \n",
      "TP: True Positive                              70        222          28   \n",
      "TN: True Negative                            1135        892        1182   \n",
      "FP: False Positive                              2         14           0   \n",
      "FN: False Negative                             13         92          10   \n",
      "TPR: (Sensitivity, hit rate, recall)     0.843373   0.707006    0.736842   \n",
      "TNR=SPC: (Specificity)                   0.998241   0.984547           1   \n",
      "PPV: Pos Pred Value (Precision)          0.972222   0.940678           1   \n",
      "NPV: Neg Pred Value                      0.988676   0.906504    0.991611   \n",
      "FPR: False-out                         0.00175901  0.0154525           0   \n",
      "FDR: False Discovery Rate               0.0277778   0.059322           0   \n",
      "FNR: Miss Rate                           0.156627   0.292994    0.263158   \n",
      "ACC: Accuracy                            0.987705   0.913115    0.991803   \n",
      "F1 score                                 0.903226   0.807273    0.848485   \n",
      "MCC: Matthews correlation coefficient    0.899281   0.765423    0.854787   \n",
      "Informedness                             0.841614   0.691554    0.736842   \n",
      "Markedness                               0.960898   0.847182    0.991611   \n",
      "Prevalence                              0.0680328   0.257377   0.0311475   \n",
      "LR+: Positive likelihood ratio            479.458    45.7534         inf   \n",
      "LR-: Negative likelihood ratio           0.156902   0.297592    0.263158   \n",
      "DOR: Diagnostic odds ratio                3055.77    153.745         inf   \n",
      "FOR: False omission rate                 0.011324  0.0934959  0.00838926   \n",
      "\n",
      "Classes                                       OTH        PART        PRON  \\\n",
      "Population                                   1220        1220        1220   \n",
      "P: Condition positive                           3         303          52   \n",
      "N: Condition negative                        1217         917        1168   \n",
      "Test outcome positive                          83         278          71   \n",
      "Test outcome negative                        1137         942        1149   \n",
      "TP: True Positive                               3         276          50   \n",
      "TN: True Negative                            1137         915        1147   \n",
      "FP: False Positive                             80           2          21   \n",
      "FN: False Negative                              0          27           2   \n",
      "TPR: (Sensitivity, hit rate, recall)            1    0.910891    0.961538   \n",
      "TNR=SPC: (Specificity)                   0.934265    0.997819    0.982021   \n",
      "PPV: Pos Pred Value (Precision)         0.0361446    0.992806    0.704225   \n",
      "NPV: Neg Pred Value                             1    0.971338    0.998259   \n",
      "FPR: False-out                          0.0657354  0.00218103   0.0179795   \n",
      "FDR: False Discovery Rate                0.963855  0.00719424    0.295775   \n",
      "FNR: Miss Rate                                  0   0.0891089   0.0384615   \n",
      "ACC: Accuracy                            0.934426     0.97623    0.981148   \n",
      "F1 score                                0.0697674    0.950086    0.813008   \n",
      "MCC: Matthews correlation coefficient    0.183762    0.936016    0.814147   \n",
      "Informedness                             0.934265     0.90871    0.943559   \n",
      "Markedness                              0.0361446    0.964143    0.702485   \n",
      "Prevalence                             0.00245902    0.248361    0.042623   \n",
      "LR+: Positive likelihood ratio            15.2125     417.644     53.4799   \n",
      "LR-: Negative likelihood ratio                  0   0.0893037   0.0391657   \n",
      "DOR: Diagnostic odds ratio                    inf     4676.67     1365.48   \n",
      "FOR: False omission rate                        0   0.0286624  0.00174064   \n",
      "\n",
      "Classes                                      SYM       VERB  \n",
      "Population                                  1220       1220  \n",
      "P: Condition positive                         87        143  \n",
      "N: Condition negative                       1133       1077  \n",
      "Test outcome positive                         87        150  \n",
      "Test outcome negative                       1133       1070  \n",
      "TP: True Positive                             87         99  \n",
      "TN: True Negative                           1133       1026  \n",
      "FP: False Positive                             0         51  \n",
      "FN: False Negative                             0         44  \n",
      "TPR: (Sensitivity, hit rate, recall)           1   0.692308  \n",
      "TNR=SPC: (Specificity)                         1   0.952646  \n",
      "PPV: Pos Pred Value (Precision)                1       0.66  \n",
      "NPV: Neg Pred Value                            1   0.958879  \n",
      "FPR: False-out                                 0  0.0473538  \n",
      "FDR: False Discovery Rate                      0       0.34  \n",
      "FNR: Miss Rate                                 0   0.307692  \n",
      "ACC: Accuracy                                  1   0.922131  \n",
      "F1 score                                       1   0.675768  \n",
      "MCC: Matthews correlation coefficient          1   0.631782  \n",
      "Informedness                                   1   0.644954  \n",
      "Markedness                                     1   0.618879  \n",
      "Prevalence                             0.0713115   0.117213  \n",
      "LR+: Positive likelihood ratio               inf    14.6199  \n",
      "LR-: Negative likelihood ratio                 0   0.322987  \n",
      "DOR: Diagnostic odds ratio                   inf    45.2647  \n",
      "FOR: False omission rate                       0  0.0411215  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8245901639344262"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import f1_score\n",
    "import tagger_evaluator as te\n",
    "\n",
    "words = te.tag_test_sentences()\n",
    "y_true = te.extract_actual_pos_tags()\n",
    "y_pred = te.extract_predicted_pos_tags(words=words)\n",
    "confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "confusion_matrix.print_stats()\n",
    "\n",
    "f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63043478, 0.89108911, 0.88135593, 0.90322581, 0.80727273,\n",
       "       0.84848485, 0.06976744, 0.95008606, 0.81300813, 1.        ,\n",
       "       0.67576792])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([0.61538462, 0.89108911, 0.88135593, 0.90322581, 0.80580762,\n",
    "       0.84848485, 0.06976744, 0.95008606, 0.81300813, 1.        ,\n",
    "       0.67576792])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
